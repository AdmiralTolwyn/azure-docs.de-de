
<!--
    As of 2017/10/06, this 'include' file is meant to replace the first paragraph of plain text that is duplicated at the top inside every tutorial-*.md article in azure-docs-pr/articles/data-factory/.

    This 'include' file is basically one paragraph.
    It explains what Azure Data Factory is, to someone who knows nothing about ADF.
-->

Azure Data Factory ist ein Datenintegrationsdienst. Er ermöglicht Ihnen die Erstellung datengesteuerter Workflows in der Cloud. Ein Workflow wird als eine oder mehrere *Pipelines* implementiert. Die Pipelines orchestrieren und automatisieren Datenverschiebung und Datentransformation. Pipelines können die folgende Sequenz mit Ihren Daten ausführen:

1. Erfassen von Daten aus unterschiedlichen Datenspeichern
2. Transformieren oder Verarbeiten der Daten mithilfe von Computediensten wie:
    - Azure HDInsight Hadoop
    - Spark
    - Azure Data Lake Analytics
    - Azure Machine Learning
3. Veröffentlichen von Ausgabedaten in Datenspeichern
    - Als Veröffentlichungsziel kann eine Azure SQL Data Warehouse-Instanz für die Nutzung durch BI-Anwendungen (Business Intelligence) festgelegt werden. 

Sie können Pipelines mithilfe von Data Factory planen.

