<properties
   pageTitle="Checkliste für die Skalierbarkeit | Microsoft Azure"
   description="Checkliste für die Skalierbarkeit für Entwurfsprobleme bei automatischer Azure-Skalierung."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>


<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="12/16/2015"
   ms.author="masashin"/>


# Checkliste für die Skalierbarkeit

![](media/best-practices-scalability-checklist/pnp-logo.png)

## Dienstentwurf
- **Partitionieren der Workload**. Entwerfen Sie Teile des Prozesses diskret und zerlegbar und minimieren Sie die Größe der einzelnen Teile, während Sie die üblichen Regeln für die Trennung von Belangen und das Single-Responsibility-Prinzip befolgen. Dadurch können Komponententeile auf eine Weise verteilt werden, die die Verwendung jeder Recheneinheit (z. B. Rolle oder Datenbankserver) maximiert und es erleichtert, die Anwendung zu skalieren, indem zusätzliche Instanzen bestimmter Ressourcen hinzugefügt werden. Weitere Informationen finden Sie unter [Leitfaden Partitionierungsberechnung](https://msdn.microsoft.com/library/dn568099.aspx).
- **Entwurf für die Skalierung**. Skalierung ermöglicht es Anwendungen, auf veränderbare Last zu reagieren, indem sie die Anzahl der Instanzen der Rollen, Warteschlangen und andere Dienste, die sie verwenden, erhöhen und verringern. Die Anwendung muss jedoch zu diesem Zweck entworfen werden. Zum Beispiel müssen Anwendung und verwendete Dienste statusfrei sein, damit Anforderungen an jede Instanz weitergeleitet werden können, außerdem darf das Hinzufügen oder Entfernen von bestimmten Instanzen keine negativen Auswirkungen auf aktuelle Benutzer haben. Es ist auch erforderlich, die Konfiguration oder automatische Erkennung von Instanzen zu implementieren, während diese hinzugefügt und entfernt werden, sodass der Code in der Anwendung das notwendige Routing ausführen kann. Eine Webanwendung kann z. B. eine Reihe von Warteschlangen in einem Roundrobin-Ansatz verwenden, um Anforderungen an Hintergrunddienste weiterzuleiten, die in Workerrollen ausgeführt werden. Die Webanwendung muss Änderungen der Anzahl der Warteschlangen erkennen können, um Anforderungen erfolgreich weiterzuleiten und den Lastenausgleich der Anwendung durchführen zu können.
- **Als Einheit skalieren**. Planen Sie die Ergänzung zusätzlicher Ressourcen, um Wachstum zu ermöglichen. Sie sollten für jede Ressource die oberen Skalierungsgrenzen kennen und Sharding oder Zerlegung verwenden, um über diese Grenzen hinausgehen. Bestimmen der Skalierungseinheiten für das System im Hinblick auf klar definierte Ressourcensätze. Dadurch ist die Anwendung der horizontalen Hochskalierung einfacher und weniger anfällig für negative Auswirkungen auf die Anwendung durch Einschränkungen, die durch den Mangel an Ressourcen in einem Teil des gesamten Systems verursacht werden. Zum Beispiel kann das Hinzufügen von X Web- und Workerrollen möglicherweise Y der zusätzliche Warteschlangen und Z Speicherkonten erforderlich machen, um die durch die Rollen generierte Workload zu bewältigen, sodass eine Skalierungseinheit aus X Web- und Workerrollen, _Y_ Warteschlangen und _Z_ Speicherkonten bestehen kann. Entwerfen Sie die Anwendung so, dass sie einfach skaliert wird, indem Sie eine oder mehrere Skalierungseinheiten hinzufügen.
- **Vermeiden von Clientaffinität**. Stellen Sie wenn möglich sicher, dass für die Anwendung keine Affinität erforderlich ist, damit Anforderungen in einer beliebigen Instanz weitergeleitet werden können und die Anzahl der Instanzen irrelevant ist. Dies verhindert auch den Aufwand für das Speichern, Abrufen und Verwalten von Zustandsinformationen für jeden einzelnen Benutzer.
- **Nutzung von Funktionen der automatischen Plattformskalierung**. Wenn die Hostingplattform eine Funktion für die automatische Skalierung unterstützt, z. B. Azure Autoscaling, bevorzugen Sie diese vor benutzerdefinierten Mechanismen oder Drittanbieter-Mechanismen, sofern der integrierte Mechanismus Ihre Anforderungen nicht erfüllen kann. Verwenden Sie wo möglich geplante Skalierungsregeln, um sicherzustellen, dass die Ressourcen ohne Startverzögerung zur Verfügung stehen. Fügen Sie jedoch automatische reaktive Skalierungsregeln hinzu, um gegebenenfalls unerwartete Änderungen der Nachfrage zu bewältigen. Sie können die Vorgänge für die automatische Skalierung in der Dienstverwaltungs-API verwenden, um die automatische Skalierung zu optimieren und benutzerdefinierte Indikatoren zu den Regeln über die Konfigurationsoptionen im Web-Portal hinzufügen. Weitere Informationen finden Sie auf der Seite [Leitfaden für die automatische Skalierung](best-practices-auto-scaling.md).
- **Offload-intensive CPU/IO-Vorgänge als Hintergrundaufgaben**. Lagern Sie die Verarbeitung für diese Anforderung in einer separaten Aufgabe aus, wenn erwartet wird, dass eine Anforderung an einen Dienst lange Zeit für die Ausführung benötigt oder beträchtliche Ressourcen absorbiert. Verwenden Sie zum Ausführen dieser Aufgaben Workerrollen oder Hintergrundaufträge (abhängig von der Hostingplattform). Dadurch kann den Dienst weiterhin Anforderungen erhalten und reaktionsfähig bleiben. Weitere Informationen finden Sie unter [Leitfaden für Hintergrundaufträge](best-practices-background-jobs.md).
- **Verteilen Sie die Workload für Hintergrundaufgaben**. Wenn es viele Hintergrundaufgaben gibt oder die Aufgaben beträchtliche Zeit oder Ressourcen erfordern, können Sie die Arbeit auf mehrere Recheneinheiten (z. B. Workerrollen oder Hintergrundaufträge) verteilen. Das [Muster „Konkurrierende Consumer“](https://msdn.microsoft.com/library/dn568101.aspx) liefert eine mögliche Lösung.
- **Erwägen Sie den Übergang zu einer Architektur _ohne gemeinsam genutzte Inhalte _ **. Eine Architektur ohne gemeinsam genutzte Inhalte verwendet unabhängige und eigenständiger Knoten, die keine einzelnen Konfliktpunkt haben, wie z. B. freigegebene Dienste oder Speicher. Theoretisch kann ein solches System fast unbegrenzt skaliert werden. Während ein vollständiger Ansatz ohne gemeinsam genutzte Inhalte im Allgemeinen für die meisten Anwendungen nicht geeignet ist, bietet er Möglichkeiten für Entwürfe mit besserer Skalierbarkeit. Die Vermeidung der Verwendung von serverseitigem Sitzungsstatus, Clientaffinität und Datenpartitionierung sind gute Beispiele für den Übergang zu einer Architektur ohne gemeinsam genutzte Inhalte.

## Datenverwaltung

- **Verwenden Sie Datenpartitionierung**. Unterteilen Sie die Daten über mehrere Datenbanken und Datenbankserver oder entwerfen Sie die Anwendung zur Verwendung von Datenspeicherdiensten, die diese Partitionierung transparent gewährleisten (zu Beispielen gehören Elastic Scale für Azure SQL-Datenbank und Azure Tabellenspeicher). Dieser Ansatz hilft bei der Leistungsmaximierung und ermöglicht einfachere Skalierung. Es gibt verschiedene Partitionierungsverfahren wie horizontale, vertikale und funktionale Partitionierung und Sie können eine Kombination dieser Verfahren nutzen, um optimalen Nutzen aus verbesserter Abfrageleistung, einfacherer Skalierbarkeit, flexiblerer Verwaltung, besserer Verfügbarkeit und eine Übereinstimmung der Art des Speichers und der darin enthaltenen Daten zu erreichen. Berücksichtigen Sie außerdem die verschiedenen Arten von Datenspeichern für verschiedene Arten von Daten. Wählen Sie die Typen basierend darauf aus, wie gut sie für den spezifischen Datentyp optimiert sind. Dazu zählt beispielsweise die Verwendung von Tabellenspeicher, einer Dokumentendatenbank oder eines Spalte-Familien-Datenspeichers anstelle von oder zusätzlich zur relationalen Datenbank. Weitere Informationen finden Sie unter [Leitfaden Datenpartitionierung](best-practices-data-partitioning.md).
- **Design für letztendliche Konsistenz**. Letztendliche Konsistenz verbessert die Skalierbarkeit durch das Reduzieren oder Entfernen des Zeitaufwands für die Synchronisierung verknüpfter Daten, die über mehrere Speicher aufgeteilt sind. Der Preis ist, dass Daten beim Lesen nicht immer konsistent sind und einige Schreibvorgänge möglicherweise Konflikte verursachen. Letztendliche Konsistenz ist ideal für Situationen, in denen die gleichen Daten oft gelesen jedoch selten geschrieben werden. Weitere Informationen finden Sie unter [Leitfaden Datenkonsistenz](#insertlink#).
- **Reduzieren Sie viele Einzelaufrufinteraktionen zwischen Komponenten und Diensten**. Vermeiden Sie das Entwerfen von _Einzelaufruf_-Schnittstellen für Dienste, bei denen eine Anwendung mehrere Aufrufe an einen Dienst ausführen muss (von denen jeder eine kleine Menge Daten zurückgibt), statt eines einzigen Aufrufs, der alle Daten zurückgeben kann. Kombinieren Sie wenn möglich mehrere verwandte Vorgänge in einer einzigen Anforderung, wenn der Aufruf eines Dienstes oder einer Komponente mit spürbarer Latenz erfolgt. Dies erleichtert die Überwachung der Leistung und die Optimierung komplexer Vorgänge. Verwenden Sie z. B. gespeicherte Prozeduren in Datenbanken, um komplexe Logik zu kapseln, und reduzieren Sie die Anzahl der Roundtrips und Sperren für Ressourcen. 
- **Verwenden Sie Warteschlangen, um die Last für Schreibvorgänge mit hoher Geschwindigkeit auszugleichen**. Nachfrageschübe für einen Dienst können diesen Dienst überlasten und eskalierende Fehler verursachen. Um dies zu verhindern, empfiehlt sich die Implementieren des [Warteschlangenbasierten Lastenausgleichsmusters](https://msdn.microsoft.com/library/dn589783.aspx). Verwenden Sie eine Warteschlange, die als Puffer zwischen einer Aufgabe und einem Dienst fungiert, den sie aufruft, um zeitweise starke Auslastung auszugleichen, die andernfalls zum Ausfall des Dienstes oder Timeout der Aufgabe führen kann.
- **Minimieren Sie die Belastung des Datenspeichers**. Der Datenspeicher ist in der Regel ein Verarbeitungsengpass, eine teure Ressource, und er lässt sich oft nicht einfach horizontal hochskalieren. Entfernen Sie nach Möglichkeit Logik (z. B. das Verarbeitung von XML-Dokumenten oder JSON-Objekten) aus dem Datenspeicher und führen Sie die Verarbeitung in der Anwendung durch. Serialisieren oder Deserialisieren Sie beispielsweise den XML-Code in der Anwendungsschicht und übergeben Sie ihn an ein datenspeichereigenes Format anstelle XML an die Datenbank zu übergeben (außer als nicht transparente Zeichenfolge für den Speicher). In der Regel ist es einfacher, die Anwendung als Datenspeicher horizontal hochzuskalieren als den Datenspeicher. Sie sollten also versuchen, einen Großteil der rechenintensiven Verarbeitung innerhalb der Anwendung auszuführen.
- **Minimieren der abgerufenen Datenmenge**. Rufen Sie nur die Daten ab, die Sie benötigen, indem Sie Spalten und Kriterien zum Auswählen von Zeilen angeben. Verwenden Sie Tabellenwertparameter und die entsprechenden Isolationsgrade. Verwenden Sie Mechanismen wie ETags, um unnötiges Abrufen von Daten zu vermeiden.
- **Verwenden Sie Zwischenspeichern aggressiv**. Verwenden Sie nach Möglichkeit Zwischenspeicherung, um die Ressourcen und Dienste zu verringern, die Daten generieren oder übermitteln. Zwischenspeichern ist in der Regel für Daten geeignet, die relativ statisch sind oder für deren Erhalt beträchtliche Verarbeitung notwendig ist. Zwischenspeichern sollte gegebenenfalls auf allen Ebenen der Anwendung erfolgen, einschließlich bei Datenzugriff und Generierung der Benutzeroberfläche. Weitere Informationen finden Sie unter [Leitfaden Zwischenspeichern](best-practices-caching.md).
- **Umgang mit Datenzuwachs und -aufbewahrung**. Die Datenmenge, die von einer Anwendung gespeichert wird, wächst mit der Zeit. Dieses Wachstum erhöht die Speicherkosten und die Latenz beim Zugriff auf die Daten – was Anwendungsdurchsatz und Leistung beeinflusst. Es ist möglich, regelmäßig einige der alten Daten zu archivieren, auf die nicht mehr zugegriffen wird, oder Daten, auf die selten zugegriffen wird, in den langfristigen Speicher zu verschieben, der kostengünstiger ist, aber eine höhere Zugriffslatenz hat.
- **Optimieren von DTOs mit einem effizienten Binärformat**. Datentransferobjekte werden viele Male zwischen den Ebenen einer Anwendung übergeben weshalb das Minimieren der Größe die Belastung von Ressourcen und Netzwerk reduziert. Gleichen Sie allerdings die Einsparungen mit dem Aufwand für die Datenkonvertierung in das erforderliche Format an jedem Verwendungsstandort aus und übernehmen Sie ein Format, das maximale Interoperabilität ermöglicht, um die einfache Wiederverwendung einer Komponente zu ermöglichen.
- **Cachesteuerung einstellen**. Entwerfen und Konfigurieren der Anwendung zum Verwenden der Ausgabezwischenspeicherung oder der Fragmentzwischenspeicherung, soweit möglich, um die Verarbeitungslast zu minimieren.
- **Aktivieren Sie clientseitiges Zwischenspeichern**. Webanwendungen sollten Cacheeinstellungen für Inhalte aktivieren, die zwischengespeichert werden können. Dies ist häufig standardmäßig deaktiviert. Konfigurieren Sie den Server für die Lieferung entsprechender Cache-Control-Header, um die Zwischenspeicherung von Inhalten auf Proxyservern und Clients zu aktivieren.
- **Verwenden von Azure Blob Storage und CDN zur Reduzierung der Auslastung der Anwendung**. Erwägen Sie die Speicherung von statischen oder relativ statischen öffentlichen Inhalten wie Bildern, Ressourcen, Skripten und Stylesheets im Blob-Speicher. Dieser Ansatz befreit die Anwendung von der Arbeitsbelastung, die durch die dynamische Generierung dieser Inhalte für jede Anforderung entsteht. Darüber hinaus sollten Sie die Verwendung des CDN zum Zwischenspeichern von Inhalten und für die Lieferung an Clients erwägen. Die Verwendung des CDN kann die Leistung auf dem Client verbessern, da Inhalte aus dem geografisch am nächsten liegenden Datencenter mit CDN-Cache übermittelt werden. Weitere Informationen finden Sie unter [Anleitungen zum Content Delivery Network (CDN)](best-practices-cdn.md).

- **Optimieren und rationalisieren Sie SQL-Abfragen und Indizes**. Einige T-SQL-Anweisungen oder Konstrukte haben möglicherweise Auswirkungen auf die Leistung, die durch die Optimierung eines Codes in einer gespeicherten Prozedur reduziert werden können. Beispielsweise sollte die Konvertierung von **Datetime**-Typen zu **varchar** vor dem Vergleich mit einem **Datetime**-Literalwert vermieden werden – verwenden Sie stattdessen die Datum/Uhrzeit-Vergleichsfunktionen. Das Fehlen geeigneter Indizes kann die Ausführung der Abfrage auch verlangsamen. Wenn Sie ein Framework für objekt-relationale Zuordnung (ORM) verwenden, stellen Sie sicher, dass Sie verstehen, wie es funktioniert und wie es sich auf die Leistung Datenzugriffsschicht auswirkt. Weitere Informationen finden Sie unter [Query Tuning](https://technet.microsoft.com/library/ms176005.aspx).
- **Erwägen Sie die Denormalisierung von Daten**. Datennormalisierung hilft, Duplizierung und Inkonsistenzen zu vermeiden. Die Verwaltung mehrerer Indizes, Prüfung auf referenzielle Integrität, Durchführung mehrerer Zugriffe auf kleine Datenblöcke und Verknüpfung von Tabellen, um die Daten wieder zusammenzusetzen, führt zu einem Aufwand, der sich auf die Leistung auswirken kann. Überlegen Sie, ob etwas zusätzliches Speichervolumen und Duplizierung akzeptabel ist, um die Last auf den Datenspeicher zu reduzieren. Berücksichtigen Sie auch, ob auf die Anwendung selbst (die in der Regel leichter zu skalieren ist) zurückgegriffen werden kann, um Aufgaben wie das Verwalten von referenzieller Integrität zu übernehmen, damit die Last auf den Datenspeicher verringert wird. Weitere Informationen finden Sie unter [Leitfaden Datenpartitionierung](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md).

## Dienstimplementierung
- **Verwenden Sie asynchrone Aufrufe**. Verwenden Sie wenn möglich asynchronen Code beim Zugriff auf Ressourcen oder Dienste, die durch E/A oder Netzwerkbandbreite beschränkt sein können oder die eine merkliche Latenz haben, um eine Sperrung des aufrufenden Threads zu vermeiden. Verwenden Sie das aufgabenbasierte asynchrone Muster, um asynchrone Vorgänge zu implementieren. Weitere Informationen finden Sie auf der Seite [Aufgabenbasiertes asynchrones Muster](https://msdn.microsoft.com/library/hh873175.aspx) auf der Microsoft-Website.
- **Vermeiden Sie das Sperren von Ressourcen und verwenden Sie stattdessen einen optimistischen Ansatz**. Sperren Sie nie den Zugriff auf Ressourcen wie z. B. Speicher oder andere Dienste, die merkliche Latenz haben, da es sich dabei um eine primäre Ursache von Leistungseinbußen handelt. Verwenden Sie immer optimistische Ansätze, um gleichzeitige Vorgänge wie z. B. das Schreiben in den Speicher zu verwalten und verwenden Sie die Funktionen der Speicherebene, um Konflikte zu bewältigen. In verteilten Anwendungen können Daten nur letztendlich konsistent sein.
- **Komprimieren Sie sehr stark komprimierbare Daten über Netzwerke mit hohen Wartezeiten und geringer Bandbreite**. In den meisten Fällen stellen in einer Webanwendung HTTP-Antworten auf Clientanforderungen die größte von der Anwendung generierte und über das Netzwerk übertragene Datenmenge. HTTP-Komprimierung kann dies besonders für statische Inhalte erheblich reduzieren. Dies kann Kosteneinsparungen und Lastverringerung auf dem Netzwerk bieten, obwohl die Komprimierung dynamischer Inhalte zu einer minimal höheren Auslastung auf dem Server führt. In anderen allgemeinen Umgebungen kann Datenkomprimierung die übertragene Datenmenge reduzieren und den Zeit- und Kostenaufwand minimieren, jedoch führen die Komprimierungs- und Dekomprimierungsprozesse zu einem Mehraufwand. Daher sollte die Komprimierung nur verwendet werden, wenn ein nachweisbarer Leistungsgewinn besteht. Andere Serialisierungsmethoden, z. B. JSON oder binäre Codierungen können die Nutzlastgröße bei geringerer Auswirkung auf die Leistung senken, wobei sich XML wahrscheinlich vergrößert.
- **Verkürzen Sie die Zeit, die Verbindungen und Ressourcen verwendet werden**. Verwalten Sie Verbindungen und Ressourcen nur, solange Sie sie verwenden müssen. Öffnen Sie Verbindungen z. B. so spät wie möglich und ermöglichen Sie die Rückgabe an den Verbindungspool so bald wie möglich. Greifen Sie auf die Ressourcen so spät wie möglich zu und entsorgen Sie sie so bald wie möglich.
- **Minimieren Sie die Anzahl der benötigten Verbindungen.**. Dienstverbindungen absorbieren Ressourcen. Begrenzen Sie wenn möglich die erforderliche Anzahl und stellen Sie sicher, dass vorhandene Verbindungen möglichst wiederverwendet werden. Verwenden Sie z. B. nach dem Ausführen der Authentifizierung gegebenenfalls den Identitätswechsel, um einen Code als bestimmte Identität auszuführen. Dies kann dabei helfen, den Verbindungspool durch die Wiederverwendung von Verbindungen optimal zu nutzen. 

	> [AZURE.NOTE]: ** APIs verwenden Verbindungen für einige Dienste automatisch wieder, sofern dienstspezifische Richtlinien eingehalten werden. Es ist wichtig, dass Sie die Umstände verstehen, unter denen eine Verbindung für jeden Dienst, die die Anwendung nutzt, erneut verwendet werden kann.
- **Stapelweises Senden von Anforderungen zur Netzwerknutzungsoptimierung**. Senden Sie z. B. Nachrichten stapelweise, wenn Sie auf eine Warteschlange zugreifen und führen Sie beim Zugriff auf Speicher oder einen Cache mehrere Lese- oder Schreibvorgänge als Batch aus. Dies kann helfen, die Effizienz der Dienste und Datenspeicher zu maximieren, indem die Anzahl der Aufrufe über das Netzwerk verringert wird.
- **Vermeiden Sie eine Anforderung zum Speichern des serverseitigen Sitzungsstatus ** wenn möglich. Serverseitige Sitzungsstatusverwaltung erfordert in der Regel Clientaffinität (also Routing jeder Anforderung zur gleichen Serverinstanz), wodurch die Skalierungsfähigkeit des Systems beeinflusst wird. Im Idealfall sollten Sie die Clients in Bezug auf die Server, die er verwendet, statusfrei entwerfen. Speichern Sie jedoch vertrauliche Daten oder große Mengen von Client-Daten in einem verteilten serverseitigen Cache, auf den alle Instanzen der Anwendung zugreifen können, wenn die Anwendung den Sitzungszustand beibehalten muss.
- **Optimieren Sie Tabellenspeicherschemas**. Bei der Verwendung von Tabellenspeichern, wie z. B. Azure-Tabellenspeicher, müssen die Tabellen- und Spaltennamen übergeben und mit jeder Abfrage verarbeitet werden. Erwägen Sie, kürzere Namen zu verwenden, um diesen zusätzlichen Aufwand zu reduzieren. Bewahren Sie allerdings Lesbarkeit und Verwaltbarkeit, obwohl Sie nicht-intuitive kompakte Namen verwenden.
- **Nutzen Sie TPL zum Ausführen asynchroner Vorgänge**. Die Task Parallel Library (TPL) erleichtert das Schreiben von asynchronem Code, der E/A-Vorgänge ausführt. Verwenden Sie _ConfigureAwait(false)_ so oft wie möglich, um die Abhängigkeit von einer Fortsetzung von einem bestimmten Synchronisierungskontext zu beseitigen und die Wahrscheinlichkeit für einen Thread-Deadlock zu reduzieren.
- **Stellen Sie Ressourcenabhängigkeiten während der Bereitstellung oder beim Anwendungsstart her**. Vermeiden Sie das wiederholte Aufrufen von Methoden, die das Vorhandensein einer Ressource testen und dann die Ressource erstellen, wenn sie nicht vorhanden ist (Methoden wie z. B. _CloudTable.CreateIfNotExists_ und _CloudQueue.CreateIfNotExists_ in der Azure-Storage-Clientbibliothek folgen diesem Muster). Diese Methoden können einen beträchtlichen Aufwand nötig machen, wenn sie vor jedem Zugriff auf einen Tabellenspeicher oder eine Speicherwarteschlange aufgerufen werden. Erstellen Sie stattdessen die erforderlichen Ressourcen, wenn die Anwendung bereitgestellt wird oder beim ersten Start (ein einzelner Aufruf an _CreateIfNotExists_ für jede Ressource im Startcode für eine Web- oder Workerrolle ist zulässig). Achten Sie jedoch darauf, Ausnahmen zu behandeln, die auftreten können, wenn der Code versucht, auf eine Ressource zuzugreifen, die nicht vorhanden ist. In diesen Fällen sollten Sie die Ausnahme protokollieren und möglicherweise einen Operator darüber benachrichtigen, dass eine Ressource fehlt. Unter bestimmten Umständen kann es angebracht sein, die fehlende Ressource im Rahmen des Ausnahmebehandlungscodes zu erstellen aber Sie sollten diesen Ansatz mit Vorsicht anwenden, da das Nichtvorhandensein der Ressource auf einen Programmierfehler (z. B. ein falsch geschriebenes Ressourcenname) oder ein anderes Problem auf Infrastrukturebene hinweisen könnte.
- **Verwenden Sie einfache Frameworks**. Wählen Sie die APIs und Frameworks die Sie verwenden sorgfältig, um die Ressourcennutzung und Ausführungszeit sowie die Gesamtlast auf die Anwendung zu minimieren. Die Verwendung von Web-API zur von Behandlung von Dienstanforderungen kann den Platzbedarf der Anwendung und die Ausführungsgeschwindigkeit erhöhen, ist aber möglicherweise nicht für fortgeschrittenere Szenarien geeignet, in denen die zusätzlichen Funktionen von WCF erforderlich sind.
- **Erwägen Sie, die Anzahl der Dienstkonten zu minimieren**. Verwenden Sie z. B. ein spezielles Konto für den Zugriff auf Ressourcen oder Dienste, die Verbindungen beschränken oder bessere Leistung bringen, wenn weniger Verbindungen verwaltet werden. Dieser Ansatz wird häufig für Dienste wie z. B. Datenbanken verwendet, kann aber die Möglichkeit zur genauen Überwachung der Vorgänge aufgrund der Identitätswechsel des ursprünglichen Benutzers beeinflussen.
- Im Rahmen der Test-Routinen während der Entwicklung **führen Sie Leistungsprofilerstellung und Auslastungstests durch** und stellen vor der endgültigen Version sicher, dass die Anwendung ausführt und nach Bedarf skaliert wird. Diese Tests sollten auf der gleichen Art von Hardware stattfinden, wie die Produktionsplattform, mit den gleichen Datentypen und -mengen sowie der Benutzerauslastung, die in der Produktion auftreten. Weitere Informationen finden Sie auf die Seite [Testen der Leistung eines Clouddiensts](https://msdn.microsoft.com/library/azure/hh369930.aspx) auf der Microsoft-Website.

<!---HONumber=AcomDC_1223_2015-->