---
title: Referenz zur Azure ML-Protokollierungs-API | Microsoft-Dokumentation
description: Referenz zur Protokollierungs-API.
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: core
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ms.openlocfilehash: 101c47f4916ca3fab56800eaf012c55150769302
ms.sourcegitcommit: e8f443ac09eaa6ef1d56a60cd6ac7d351d9271b9
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 09/12/2018
ms.locfileid: "35637641"
---
# <a name="logging-api-reference"></a>Referenz zur Protokollierungs-API

Die Protokollierungsbibliothek von Azure ML ermöglicht es dem Programm, Metriken und Dateien auszugeben, die vom Verlaufsdienst zur späteren Analyse nachverfolgt werden. Derzeit werden einige grundlegende Typen von Metriken und Dateien unterstützt, und die Gruppe der unterstützten Typen wächst mit zukünftigen Versionen des Python-Pakets.

## <a name="uploading-metrics"></a>Hochladen von Metriken

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

Standardmäßig werden alle Metriken asynchron gesendet, sodass die Übermittlung die Ausführung des Programms nicht behindert. Dies kann zu Problemen bei der Sortierung führen, wenn mehrere Metriken in Grenzfällen gesendet werden. Ein Beispiel hierfür wären zwei Metriken, die gleichzeitig protokolliert werden, aber es der Benutzer aus irgendeinem Grund vorzieht, dass ihre genaue Reihenfolge beibehalten wird. Ein weiterer Fall ist, wenn die Metrik nachverfolgt werden muss, bevor Code ausgeführt wird, der dafür bekannt ist, Fail-Fast-fähig zu sein. In beiden Fällen besteht die Lösung darin, zu _warten_, bis die Metrik vollständig protokolliert wurde, bevor der Vorgang fortgesetzt wird:

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>Verarbeiten von Metriken

Die Metriken werden vom Verlaufsdienst gespeichert und an die Ausführung gebunden, von der sie erzeugt wurden. Sowohl die Registerkarte „Ausführungsverlauf“ als auch der nachfolgende CLI-Befehl gestatten es Ihnen, sie (und untergeordnete Artefakte) nach dem Abschluss einer Ausführung abzurufen.

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>Artefakte (Dateien)

Zusätzlich zu den Metriken gestattet Azure ML dem Benutzer auch das Nachverfolgen von Dateien. Standardmäßig werden alle relativ zum Arbeitsverzeichnis des Programms (der Projektordner im Computekontext) in den Ordner `outputs` geschriebenen Dateien in den Verlaufsdienst hochgeladen und für die spätere Analyse nachverfolgt. Der Nachteil ist, dass die Größe einzelner Dateien kleiner als 512 MB sein muss.


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>Verarbeiten von Artefakten

Der Benutzer kann zum Drucken des Inhalts eines Artefakts, das nachverfolgt wurde, die Registerkarte „Ausführungsverlauf“ für die angegebene Ausführung verwenden, um das Artefakt **herunterzuladen** oder **heraufzustufen**. Der Benutzer kann aber auch die folgenden CLI-Befehle verwenden, um denselben Effekt zu erzielen.

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>Nächste Schritte
- Durchlaufen Sie das [Tutorial zum Klassifizieren von Schwertlilien, Teil 2](tutorial-classifying-iris-part-2.md), um die Protokollierungs-API in Aktion zu sehen.
- Lesen Sie [Verwenden des Ausführungsverlaufs und der Modellmetriken in Azure Machine Learning Workbench](how-to-use-run-history-model-metrics.md), um besser verstehen, wie Protokollierungs-APIs im Ausführungsverlauf verwendet werden können.
